{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c86f49-b270-42c4-8228-6a4641daafab",
   "metadata": {},
   "source": [
    "# Perceptron with predefined weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9ffdc2-1fc1-4a86-aa5b-6a9408fc9efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation function\n",
    "def predict(row,weights):\n",
    "    activation = weights[0]\n",
    "    for i in range(len(row)-1):\n",
    "        activation += weights[i+1]*row[i]\n",
    "    return 1.0 if activation >=0.0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d554e254-eea3-48d1-be08-5991c4b9e162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected=0, prediction=0\n",
      "expected=0, prediction=0\n",
      "expected=0, prediction=0\n",
      "expected=0, prediction=0\n",
      "expected=0, prediction=0\n",
      "expected=1, prediction=1\n",
      "expected=1, prediction=1\n",
      "expected=1, prediction=1\n",
      "expected=1, prediction=1\n",
      "expected=1, prediction=1\n"
     ]
    }
   ],
   "source": [
    "#test predictions\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "\t[1.465489372,2.362125076,0],\n",
    "\t[3.396561688,4.400293529,0],\n",
    "\t[1.38807019,1.850220317,0],\n",
    "\t[3.06407232,3.005305973,0],\n",
    "\t[7.627531214,2.759262235,1],\n",
    "\t[5.332441248,2.088626775,1],\n",
    "\t[6.922596716,1.77106367,1],\n",
    "\t[8.675418651,-0.242068655,1],\n",
    "\t[7.673756466,3.508563011,1]]\n",
    "weights = [-0.1, 0.20653640140000007, -0.23418117710000003]\n",
    "for row in dataset:\n",
    "    prediction = predict(row,weights)\n",
    "    print(\"expected=%d, prediction=%d\" % (row[-1],prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "013ee725-55bf-4d61-bc17-c177dc09e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimating weights using stocastic gradient \n",
    "def predict(row,weights):\n",
    "    activation = weights[0]\n",
    "    for i in range(len(row)-1):\n",
    "        activation += weights[i+1]*row[i]\n",
    "    return 1 if activation >= 0 else 0\n",
    "\n",
    "def train_weights(train, lrate, nepoch):\n",
    "    weights = [0.0 for i in range(len(train[0]))]\n",
    "    for epoch in range(nepoch):\n",
    "        sum_error =  0\n",
    "        for row in train:\n",
    "            prediction = predict(row,weights)\n",
    "            e = row[-1]-prediction\n",
    "            sum_error = e**2\n",
    "            weights[0] = weights[0]+lrate*e\n",
    "            for i in range(len(row)-1):\n",
    "                weights[i+1] = weights[i+1] + lrate*e*row[i]\n",
    "        print(\"epoch=%d , lrate=%.3f, error=%.3f\" % (epoch,lrate,sum_error))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed04ca3-7180-4ccc-974e-8bb176d3c923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 , lrate=0.100, error=1.000\n",
      "epoch=1 , lrate=0.100, error=1.000\n",
      "epoch=2 , lrate=0.100, error=1.000\n",
      "epoch=3 , lrate=0.100, error=0.000\n",
      "epoch=4 , lrate=0.100, error=0.000\n",
      "\n",
      "\n",
      "[-0.20000000000000004, 0.2, 0.1]\n",
      "\n",
      "\n",
      "Expected=0.000000 , Predicted =0.000000\n",
      "Expected=0.000000 , Predicted =0.000000\n",
      "Expected=0.000000 , Predicted =0.000000\n",
      "Expected=1.000000 , Predicted =1.000000\n"
     ]
    }
   ],
   "source": [
    "#And Dataset\n",
    "dataset = [[0,0,0],\n",
    "          [0,1,0],\n",
    "          [1,0,0,],\n",
    "          [1,1,1]]\n",
    "           \n",
    "lrate = 0.1\n",
    "nepoch = 5\n",
    "weights = train_weights(dataset,lrate,nepoch)\n",
    "print(\"\\n\")\n",
    "print(weights)\n",
    "print(\"\\n\")\n",
    "\n",
    "for row in dataset:\n",
    "    prediction = predict(row,weights)\n",
    "    print(\"Expected=%f , Predicted =%f\" % (row[-1], prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d881c17-15f9-43a6-be5d-4180d8815309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected = 0, Prediction = 0\n",
      "Expected = 1, Prediction = 1\n",
      "Expected = 1, Prediction = 1\n",
      "Expected = 1, Prediction = 1\n",
      "\n",
      "\n",
      "epoch=0 , lrate=0.100, error=0.000\n",
      "epoch=1 , lrate=0.100, error=0.000\n",
      "epoch=2 , lrate=0.100, error=0.000\n",
      "epoch=3 , lrate=0.100, error=0.000\n",
      "epoch=4 , lrate=0.100, error=0.000\n",
      "\n",
      "\n",
      "[-0.1, 0.1, 0.1]\n"
     ]
    }
   ],
   "source": [
    "#OR\n",
    "dataset = [[0, 0, 0],\n",
    "\t[0, 1, 1],\n",
    "\t[1, 0, 1],\n",
    "\t[1, 1, 1]]\n",
    "weights = [-0.5, 1, 1]\n",
    "\n",
    "for row in dataset:\n",
    "    prediction = predict(row,weights)\n",
    "    print(f\"Expected = {row[-1]}, Prediction = {prediction}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "lrate = 0.1\n",
    "nepoch = 5\n",
    "weights = train_weights(dataset,lrate,nepoch)\n",
    "print(\"\\n\")\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f415c447-379e-404c-8aaf-3e8ef2ff5696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 , lrate=0.100, error=1.000\n",
      "epoch=1 , lrate=0.100, error=1.000\n",
      "epoch=2 , lrate=0.100, error=1.000\n",
      "epoch=3 , lrate=0.100, error=1.000\n",
      "epoch=4 , lrate=0.100, error=1.000\n",
      "[0.0, -0.1, 0.0]\n"
     ]
    }
   ],
   "source": [
    "#XOR dataset\n",
    "dataset = [\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0]\n",
    "]\n",
    "lrate = 0.1\n",
    "nepoch = 5\n",
    "weights = train_weights(dataset, lrate, nepoch)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d34bf8f-8ccc-4bda-bfa9-a49729cb07e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since error is increasing model is not appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b67fbc9-3f6a-4b04-82e5-a65d11f25dda",
   "metadata": {},
   "source": [
    "# Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5733fa4e-d624-4ecb-b15b-0272260c0f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid\n",
    "\n",
    "import math\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def predict(row,weights):\n",
    "    activation = weights[0]\n",
    "    for i in range(len(row)-1):\n",
    "        activation += weights[i+1]*row[i]\n",
    "    y = sigmoid(activation)\n",
    "    return 1 if y>0.5 else 0.0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe0f500d-0b1d-47da-b25d-8d4baae4eace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected = 0,  Prediction = 0.0\n",
      "Expected = 0,  Prediction = 0.0\n",
      "Expected = 0,  Prediction = 0.0\n",
      "Expected = 0,  Prediction = 0.0\n",
      "Expected = 0,  Prediction = 0.0\n",
      "Expected = 1,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n"
     ]
    }
   ],
   "source": [
    "# Test predictions\n",
    "dataset = [\n",
    "    [2.7810836, 2.550537003, 0],\n",
    "    [1.465489372, 2.362125076, 0],\n",
    "    [3.396561688, 4.400293529, 0],\n",
    "    [1.38807019, 1.850220317, 0],\n",
    "    [3.06407232, 3.005305973, 0],\n",
    "    [7.627531214, 2.759262235, 1],\n",
    "    [5.332441248, 2.088626775, 1],\n",
    "    [6.922596716, 1.77106367, 1],\n",
    "    [8.675418651, -0.242068655, 1],\n",
    "    [7.673756466, 3.508563011, 1]\n",
    "]\n",
    "\n",
    "weights = [-0.1, 0.20653640140000007, -0.23418117710000003]\n",
    "\n",
    "for row in dataset:\n",
    "    prediction = predict(row,weights)\n",
    "    print(f\"Expected = {row[-1]},  Prediction = {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d31e6675-cd6d-42f9-b443-d832f033ee21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 , lrate=0.100, error=0.000\n",
      "epoch=1 , lrate=0.100, error=0.000\n",
      "epoch=2 , lrate=0.100, error=0.000\n",
      "epoch=3 , lrate=0.100, error=0.000\n",
      "epoch=4 , lrate=0.100, error=0.000\n",
      "[-0.2, 0.4830844168000002, -0.6344968141]\n",
      "\n",
      "\n",
      "Expected = 0,  Prediction = 0.0\n",
      "Expected = 0,  Prediction = 0.0\n",
      "Expected = 0,  Prediction = 0.0\n",
      "Expected = 0,  Prediction = 0.0\n",
      "Expected = 0,  Prediction = 0.0\n",
      "Expected = 1,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n"
     ]
    }
   ],
   "source": [
    "dataset = [\n",
    "    [2.7810836, 2.550537003, 0],\n",
    "    [1.465489372, 2.362125076, 0],\n",
    "    [3.396561688, 4.400293529, 0],\n",
    "    [1.38807019, 1.850220317, 0],\n",
    "    [3.06407232, 3.005305973, 0],\n",
    "    [7.627531214, 2.759262235, 1],\n",
    "    [5.332441248, 2.088626775, 1],\n",
    "    [6.922596716, 1.77106367, 1],\n",
    "    [8.675418651, -0.242068655, 1],\n",
    "    [7.673756466, 3.508563011, 1]\n",
    "]\n",
    "lrate = 0.1\n",
    "nepoch = 5\n",
    "\n",
    "weights1 = train_weights(dataset, lrate,nepoch)\n",
    "print(weights1)\n",
    "print(\"\\n\")\n",
    "for row in dataset:\n",
    "    prediction = predict(row,weights1)\n",
    "    print(f\"Expected = {row[-1]},  Prediction = {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4806ab90-d5f5-4f83-aab6-e8e84f6926fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tanh activation function\n",
    "\n",
    "def tanh(x):\n",
    "    return(math.exp(x)-math.exp(-x))/(math.exp(x) + math.exp(-x))\n",
    "\n",
    "def predict(row,weights):\n",
    "    activation = weights[0]\n",
    "    for i in range(len(row)-1):\n",
    "        activation += weights[i+1]*row[i]\n",
    "    y = tanh(activation)\n",
    "    return 1 if y>0 else 0.0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3cc41a9-53e2-41e4-8b27-c76abab9a858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 , lrate=0.100, error=0.000\n",
      "epoch=1 , lrate=0.100, error=0.000\n",
      "epoch=2 , lrate=0.100, error=0.000\n",
      "epoch=3 , lrate=0.100, error=0.000\n",
      "epoch=4 , lrate=0.100, error=0.000\n",
      "[-0.2, 0.4830844168000002, -0.6344968141]\n",
      "\n",
      "\n",
      "Expected = 0,  Prediction = 0.0\n",
      "Expected = 0,  Prediction = 0.0\n",
      "Expected = 0,  Prediction = 0.0\n",
      "Expected = 0,  Prediction = 0.0\n",
      "Expected = 0,  Prediction = 0.0\n",
      "Expected = 1,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n"
     ]
    }
   ],
   "source": [
    "dataset = [\n",
    "    [2.7810836, 2.550537003, 0],\n",
    "    [1.465489372, 2.362125076, 0],\n",
    "    [3.396561688, 4.400293529, 0],\n",
    "    [1.38807019, 1.850220317, 0],\n",
    "    [3.06407232, 3.005305973, 0],\n",
    "    [7.627531214, 2.759262235, 1],\n",
    "    [5.332441248, 2.088626775, 1],\n",
    "    [6.922596716, 1.77106367, 1],\n",
    "    [8.675418651, -0.242068655, 1],\n",
    "    [7.673756466, 3.508563011, 1]\n",
    "]\n",
    "lrate = 0.1\n",
    "nepoch = 5\n",
    "\n",
    "weights1 = train_weights(dataset, lrate,nepoch)\n",
    "print(weights1)\n",
    "print(\"\\n\")\n",
    "for row in dataset:\n",
    "    prediction = predict(row,weights1)\n",
    "    print(f\"Expected = {row[-1]},  Prediction = {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff4c06af-5257-462c-a5af-128da9d3f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu Activation Function\n",
    "\n",
    "def relu(x):\n",
    "    return max(0,x)\n",
    "\n",
    "def predict(row, weights):\n",
    "    activation = weights[0]\n",
    "    for i in range(len(row)-1):\n",
    "        activation += weights[i+1]*row[i]\n",
    "    y = relu(activation)\n",
    "    return 1 if y>= 0  else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e731683d-a5eb-4897-ac0f-9c8e2874a0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 , lrate=0.100, error=0.000\n",
      "epoch=1 , lrate=0.100, error=0.000\n",
      "epoch=2 , lrate=0.100, error=0.000\n",
      "epoch=3 , lrate=0.100, error=0.000\n",
      "epoch=4 , lrate=0.100, error=0.000\n",
      "[-2.500000000000001, -6.0476385850000005, -7.084240949000001]\n",
      "\n",
      "\n",
      "Expected = 0,  Prediction = 1\n",
      "Expected = 0,  Prediction = 1\n",
      "Expected = 0,  Prediction = 1\n",
      "Expected = 0,  Prediction = 1\n",
      "Expected = 0,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n",
      "Expected = 1,  Prediction = 1\n"
     ]
    }
   ],
   "source": [
    "dataset = [\n",
    "    [2.7810836, 2.550537003, 0],\n",
    "    [1.465489372, 2.362125076, 0],\n",
    "    [3.396561688, 4.400293529, 0],\n",
    "    [1.38807019, 1.850220317, 0],\n",
    "    [3.06407232, 3.005305973, 0],\n",
    "    [7.627531214, 2.759262235, 1],\n",
    "    [5.332441248, 2.088626775, 1],\n",
    "    [6.922596716, 1.77106367, 1],\n",
    "    [8.675418651, -0.242068655, 1],\n",
    "    [7.673756466, 3.508563011, 1]\n",
    "]\n",
    "lrate = 0.1\n",
    "nepoch = 5\n",
    "\n",
    "weights1 = train_weights(dataset, lrate,nepoch)\n",
    "print(weights1)\n",
    "print(\"\\n\")\n",
    "for row in dataset:\n",
    "    prediction = predict(row,weights1)\n",
    "    print(f\"Expected = {row[-1]},  Prediction = {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b9aec4-e164-4441-9d9c-00b1904d2e5c",
   "metadata": {},
   "source": [
    "# Fuzzy Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "657f88c2-1e8b-4f73-a25d-1495aa992eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Rule\n",
      "\n",
      "Rule 1: If Temperature is Below Average and Pressure is Below Average, then Heating Power is Medium High and Valve Opening is Medium Low.\n",
      "\n",
      "Rule 2: If Temperature is Low and Pressure is Low, then Heating Power is High and Valve Opening is Small.\n",
      "\n",
      "Fuzzification Results:\n",
      "Temperature (Below Average): 0.16666666666666666\n",
      "Temperature (Low): 0.5\n",
      "Pressure (Below Average): 0.06666666666666672\n",
      "Pressure (Low): 0.6\n",
      "\n",
      "Rule Evaluation Results:\n",
      "Rule 1 Strength: 0.06666666666666672\n",
      "Rule 2 Strength: 0.5\n",
      "\n",
      "Defuzzification Results:\n",
      "Crisp Heating Power: 4.88235294117647\n",
      "Crisp Valve Opening: 0.6333333333333334\n"
     ]
    }
   ],
   "source": [
    "# Trangular Membership function\n",
    "def trig(x,l,c,r):\n",
    "    if x < l or x > r:\n",
    "        return 0\n",
    "    elif l <= x <= c:\n",
    "        return (x - l)/(c - l)\n",
    "    else:\n",
    "        return (r - x)/(r - c)\n",
    "\n",
    "def fuzzification(temperature, pressure):\n",
    "    \"\"\"Fuzzifies the input values using triangular membership functions.\"\"\"\n",
    "    temp_BA = trig(temperature, 15, 30, 45)\n",
    "    temp_low = trig(temperature, -5, 10, 25)\n",
    "    press_BA = trig(pressure, 1.25, 2, 2.75)\n",
    "    press_low = trig(pressure, 0.25, 1, 1.75)\n",
    "\n",
    "    print(\"\\nFuzzification Results:\")\n",
    "    print(f\"Temperature (Below Average): {temp_BA}\")\n",
    "    print(f\"Temperature (Low): {temp_low}\")\n",
    "    print(f\"Pressure (Below Average): {press_BA}\")\n",
    "    print(f\"Pressure (Low): {press_low}\")\n",
    "\n",
    "    return temp_BA, temp_low, press_BA, press_low\n",
    "\n",
    "#Rules\n",
    "print(\"Evaluation Rule\")\n",
    "print(\"\\nRule 1: If Temperature is Below Average and Pressure is Below Average, then Heating Power is Medium High and Valve Opening is Medium Low.\")\n",
    "print(\"\\nRule 2: If Temperature is Low and Pressure is Low, then Heating Power is High and Valve Opening is Small.\")\n",
    "\n",
    "\n",
    "def rule_evaluation(temp_BA, temp_low, press_BA, press_low):\n",
    "    \"\"\"Evaluates the fuzzy rules using the minimum operator.\"\"\"\n",
    "    z1 = min(temp_BA, press_BA)\n",
    "    z2 = min(temp_low, press_low)\n",
    "\n",
    "    print(\"\\nRule Evaluation Results:\")\n",
    "    print(f\"Rule 1 Strength: {z1}\")\n",
    "    print(f\"Rule 2 Strength: {z2}\")\n",
    "\n",
    "    return z1,z2\n",
    "\n",
    "def area_cen(l,c,r):\n",
    "    area = 0.5*1*(r-l)\n",
    "    cen = c\n",
    "    return area,cen\n",
    "\n",
    "def defuzzification(z1, z2):\n",
    "    \"\"\"Defuzzifies the output using (Rule Strength × Area × Centroid).\"\"\"\n",
    "    # Define fuzzy output sets\n",
    "    area1, cen1 = area_cen(3.25, 4, 4.75)  # Heating Power Medium-High\n",
    "    area2, cen2 = area_cen(4.25, 5, 5.75)  # Heating Power High\n",
    "\n",
    "    area3, cen3 = area_cen(1.25, 2, 2.75)  # Valve Opening Medium-Low\n",
    "    area4, cen4 = area_cen(0.25, 1, 1.75)  # Valve Opening Low\n",
    "\n",
    "    # Defuzzification formula\n",
    "    hp = (z1 * area1 * cen1 + z2 * area2 * cen2) / \\\n",
    "                          (z1 * area1 + z2 * area2)\n",
    "\n",
    "    vo = (z1 * area3 * cen3 + z2 * area4 * cen4) / \\\n",
    "                          (z2 * area3 + z2 * area4)\n",
    "\n",
    "    print(\"\\nDefuzzification Results:\")\n",
    "    print(f\"Crisp Heating Power: {hp}\")\n",
    "    print(f\"Crisp Valve Opening: {vo}\")\n",
    "\n",
    "    return hp, vo\n",
    "\n",
    "# Input values\n",
    "temperature = 17.5\n",
    "pressure = 1.3\n",
    "\n",
    "# Execute Fuzzy Logic System\n",
    "temp_BA, temp_low, press_BA, press_low = fuzzification(temperature, pressure)\n",
    "z1, z2 = rule_evaluation(temp_BA, temp_low, press_BA, press_low)\n",
    "hp, vo = defuzzification(z1, z2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bdb0c48-7d0e-4f9b-97e8-a9fb89156a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fuzzification Results :\n",
      "Temperature(Below Average): 0.75\n",
      "Temperature (Low): 0.75\n",
      "Pressure (Below Average): 0.6000000000000001\n",
      "Pressure (Low): 0.3999999999999999\n",
      "\n",
      "Rule Evaluation Results:\n",
      "Rule 1 Strength: 0.6000000000000001\n",
      "Rule 2 Strength: 0.3999999999999999\n",
      "\n",
      "Defuzzification Results:\n",
      "Crisp Heating Power: 4.5\n",
      "Crisp Valve Opening: 2.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "#Trapezoidal Membership Function\n",
    "def trapezoidal(x,l,c1,c2,r):\n",
    "    if x < l or x > r:\n",
    "        return 0\n",
    "    elif l <= x < c1:\n",
    "        return (x - l)/(c1 - l)\n",
    "    elif c1 <= x < c2:\n",
    "        return (x - c1)/(c2 - c1)\n",
    "    else :\n",
    "        return (r - x)/(r - c2)\n",
    "\n",
    "def fuzzification(temparture,pressure):\n",
    "    temp_BA = trapezoidal(temperature,10,20,30,40)\n",
    "    temp_low = trapezoidal(temperature, -5, 5, 15, 25)\n",
    "    press_BA = trapezoidal(pressure, 1, 1.5, 2, 2.5)\n",
    "    press_low = trapezoidal(pressure, 0, 0.5, 1, 1.5)\n",
    "\n",
    "    print(\"\\n Fuzzification Results :\")\n",
    "    print(f\"Temperature(Below Average): {temp_BA}\")\n",
    "    print(f\"Temperature (Low): {temp_low}\")\n",
    "    print(f\"Pressure (Below Average): {press_BA}\")\n",
    "    print(f\"Pressure (Low): {press_low}\")\n",
    "\n",
    "    return temp_BA,temp_low,press_BA,press_low\n",
    "\n",
    "def rule_evaluation(temp_BA,temp_low,press_BA,press_low):\n",
    "    z1 = min(temp_BA,press_BA)\n",
    "    z2 = min(temp_low,press_low)\n",
    "\n",
    "    print(\"\\nRule Evaluation Results:\")\n",
    "    print(f\"Rule 1 Strength: {z1}\")\n",
    "    print(f\"Rule 2 Strength: {z2}\")\n",
    "\n",
    "    return z1, z2\n",
    "\n",
    "def area_cen(l,c1,c2,r):\n",
    "    area = 0.5*((c1-c2)+(r-l))*1\n",
    "    cen = (l + c1 + c2 + r)/4\n",
    "    return area, cen\n",
    "\n",
    "def defuzzification(z1, z2):\n",
    "    \"\"\"Defuzzifies the output using (Rule Strength × Area × Centroid).\"\"\"\n",
    "    # Define fuzzy output sets\n",
    "    area1, cen1 = area_cen(3,3.5, 4.5, 5)  # Heating Power Medium-High\n",
    "    area2, cen2 = area_cen(4.5, 5, 5.5,6)  # Heating Power High\n",
    "\n",
    "    area3, cen3 = area_cen(1,1.5, 2.5, 3)  # Valve Opening Medium-Low\n",
    "    area4, cen4 = area_cen(0,0.5, 1.5, 2)  # Valve Opening Low\n",
    "\n",
    "    # Defuzzification formula\n",
    "    hp = (z1 * area1 * cen1 + z2 * area2 * cen2) / \\\n",
    "                          (z1 * area1 + z2 * area2)\n",
    "\n",
    "    vo = (z1 * area3 * cen3 + z2 * area4 * cen4) / \\\n",
    "                          (z2 * area3 + z2 * area4)\n",
    "\n",
    "    print(\"\\nDefuzzification Results:\")\n",
    "    print(f\"Crisp Heating Power: {hp}\")\n",
    "    print(f\"Crisp Valve Opening: {vo}\")\n",
    "\n",
    "    return hp, vo\n",
    "\n",
    "# Input values\n",
    "temperature = 17.5\n",
    "pressure = 1.3\n",
    "\n",
    "# Execute Fuzzy Logic System\n",
    "temp_BA, temp_low, press_BA, press_low = fuzzification(temperature, pressure)\n",
    "z1, z2 = rule_evaluation(temp_BA, temp_low, press_BA, press_low)\n",
    "hp, vo = defuzzification(z1, z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc3684f-c2cd-4a5e-bd67-77c1e579b9c1",
   "metadata": {},
   "source": [
    "# first neural network with keras tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e91c85db-43d3-42b4-bf37-d470c0c56ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\vinay\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\vinay\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinay\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5974 - loss: 4.3538 \n",
      "Epoch 2/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6399 - loss: 1.7310\n",
      "Epoch 3/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6402 - loss: 1.3361\n",
      "Epoch 4/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6493 - loss: 1.1036\n",
      "Epoch 5/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6390 - loss: 1.2243\n",
      "Epoch 6/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6321 - loss: 0.9722\n",
      "Epoch 7/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6075 - loss: 0.9793\n",
      "Epoch 8/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6232 - loss: 0.9419\n",
      "Epoch 9/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6668 - loss: 0.7897  \n",
      "Epoch 10/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6325 - loss: 0.8255  \n",
      "Epoch 11/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6207 - loss: 0.7572  \n",
      "Epoch 12/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.6079 - loss: 0.7631\n",
      "Epoch 13/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6408 - loss: 0.7413\n",
      "Epoch 14/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.6440 - loss: 0.7191\n",
      "Epoch 15/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6390 - loss: 0.6986  \n",
      "Epoch 16/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6612 - loss: 0.6804  \n",
      "Epoch 17/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6935 - loss: 0.6245\n",
      "Epoch 18/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6788 - loss: 0.7112  \n",
      "Epoch 19/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6825 - loss: 0.6439\n",
      "Epoch 20/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6542 - loss: 0.7569\n",
      "Epoch 21/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6726 - loss: 0.6468  \n",
      "Epoch 22/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6594 - loss: 0.6398\n",
      "Epoch 23/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6797 - loss: 0.6394\n",
      "Epoch 24/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6422 - loss: 0.6810\n",
      "Epoch 25/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6556 - loss: 0.6926\n",
      "Epoch 26/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6809 - loss: 0.6466\n",
      "Epoch 27/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6567 - loss: 0.6278\n",
      "Epoch 28/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6936 - loss: 0.6068\n",
      "Epoch 29/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6696 - loss: 0.6196\n",
      "Epoch 30/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6960 - loss: 0.5875  \n",
      "Epoch 31/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6998 - loss: 0.5812\n",
      "Epoch 32/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6909 - loss: 0.6063\n",
      "Epoch 33/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7092 - loss: 0.6054\n",
      "Epoch 34/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7014 - loss: 0.6112\n",
      "Epoch 35/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6844 - loss: 0.6227\n",
      "Epoch 36/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7272 - loss: 0.5750\n",
      "Epoch 37/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7030 - loss: 0.6039\n",
      "Epoch 38/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6699 - loss: 0.6520\n",
      "Epoch 39/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6816 - loss: 0.7594\n",
      "Epoch 40/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7236 - loss: 0.5891\n",
      "Epoch 41/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7521 - loss: 0.5515\n",
      "Epoch 42/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7405 - loss: 0.5534\n",
      "Epoch 43/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7102 - loss: 0.6043\n",
      "Epoch 44/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7202 - loss: 0.6045\n",
      "Epoch 45/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7032 - loss: 0.5591\n",
      "Epoch 46/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6847 - loss: 0.6109\n",
      "Epoch 47/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7205 - loss: 0.5813  \n",
      "Epoch 48/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7112 - loss: 0.6102\n",
      "Epoch 49/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7129 - loss: 0.6025\n",
      "Epoch 50/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7346 - loss: 0.5446\n",
      "Epoch 51/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7506 - loss: 0.5444\n",
      "Epoch 52/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7287 - loss: 0.5650\n",
      "Epoch 53/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7030 - loss: 0.6348\n",
      "Epoch 54/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7115 - loss: 0.5798\n",
      "Epoch 55/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7222 - loss: 0.5926\n",
      "Epoch 56/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7359 - loss: 0.5517\n",
      "Epoch 57/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7283 - loss: 0.5616\n",
      "Epoch 58/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7157 - loss: 0.5561\n",
      "Epoch 59/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7497 - loss: 0.5486\n",
      "Epoch 60/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7480 - loss: 0.5213\n",
      "Epoch 61/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6700 - loss: 0.6394\n",
      "Epoch 62/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7310 - loss: 0.5342\n",
      "Epoch 63/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7268 - loss: 0.5960\n",
      "Epoch 64/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6815 - loss: 0.6202\n",
      "Epoch 65/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7404 - loss: 0.5487\n",
      "Epoch 66/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6973 - loss: 0.5758\n",
      "Epoch 67/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7382 - loss: 0.5510\n",
      "Epoch 68/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7023 - loss: 0.5783\n",
      "Epoch 69/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6945 - loss: 0.5699\n",
      "Epoch 70/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7485 - loss: 0.5291\n",
      "Epoch 71/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6850 - loss: 0.6107\n",
      "Epoch 72/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7251 - loss: 0.5423\n",
      "Epoch 73/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7376 - loss: 0.5437\n",
      "Epoch 74/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7502 - loss: 0.5549\n",
      "Epoch 75/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7223 - loss: 0.5741\n",
      "Epoch 76/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7163 - loss: 0.5618  \n",
      "Epoch 77/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7517 - loss: 0.5104\n",
      "Epoch 78/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7240 - loss: 0.5777\n",
      "Epoch 79/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7171 - loss: 0.5317\n",
      "Epoch 80/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7266 - loss: 0.5539\n",
      "Epoch 81/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7562 - loss: 0.5182\n",
      "Epoch 82/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7216 - loss: 0.5422\n",
      "Epoch 83/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7257 - loss: 0.5613\n",
      "Epoch 84/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7207 - loss: 0.5535\n",
      "Epoch 85/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7590 - loss: 0.5361\n",
      "Epoch 86/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7302 - loss: 0.5803\n",
      "Epoch 87/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7218 - loss: 0.5639\n",
      "Epoch 88/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7405 - loss: 0.5387\n",
      "Epoch 89/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7409 - loss: 0.5319\n",
      "Epoch 90/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7504 - loss: 0.5216\n",
      "Epoch 91/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7585 - loss: 0.5261\n",
      "Epoch 92/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7754 - loss: 0.4983\n",
      "Epoch 93/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7519 - loss: 0.5022\n",
      "Epoch 94/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7352 - loss: 0.5763\n",
      "Epoch 95/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7462 - loss: 0.5147\n",
      "Epoch 96/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7430 - loss: 0.5744\n",
      "Epoch 97/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7301 - loss: 0.5574  \n",
      "Epoch 98/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7637 - loss: 0.4922\n",
      "Epoch 99/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7261 - loss: 0.5344\n",
      "Epoch 100/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7363 - loss: 0.5124\n",
      "Epoch 101/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7107 - loss: 0.5699\n",
      "Epoch 102/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7472 - loss: 0.5160  \n",
      "Epoch 103/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7522 - loss: 0.5389\n",
      "Epoch 104/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7288 - loss: 0.5214\n",
      "Epoch 105/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7441 - loss: 0.5217\n",
      "Epoch 106/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7262 - loss: 0.5498\n",
      "Epoch 107/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7769 - loss: 0.4921\n",
      "Epoch 108/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7591 - loss: 0.4898\n",
      "Epoch 109/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7431 - loss: 0.5291\n",
      "Epoch 110/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7411 - loss: 0.5140\n",
      "Epoch 111/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7163 - loss: 0.6183\n",
      "Epoch 112/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7269 - loss: 0.5251\n",
      "Epoch 113/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7660 - loss: 0.4762\n",
      "Epoch 114/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7538 - loss: 0.5005\n",
      "Epoch 115/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7497 - loss: 0.5235  \n",
      "Epoch 116/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7565 - loss: 0.4977\n",
      "Epoch 117/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7701 - loss: 0.4955\n",
      "Epoch 118/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7445 - loss: 0.5276\n",
      "Epoch 119/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7724 - loss: 0.4787\n",
      "Epoch 120/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7781 - loss: 0.5038\n",
      "Epoch 121/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7607 - loss: 0.4985\n",
      "Epoch 122/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7577 - loss: 0.4968\n",
      "Epoch 123/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7763 - loss: 0.5124\n",
      "Epoch 124/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7418 - loss: 0.5230\n",
      "Epoch 125/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7660 - loss: 0.4883\n",
      "Epoch 126/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7607 - loss: 0.4931\n",
      "Epoch 127/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7768 - loss: 0.4942\n",
      "Epoch 128/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7850 - loss: 0.5062\n",
      "Epoch 129/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7587 - loss: 0.5047\n",
      "Epoch 130/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7320 - loss: 0.5384\n",
      "Epoch 131/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7764 - loss: 0.4903\n",
      "Epoch 132/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7519 - loss: 0.5390  \n",
      "Epoch 133/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7506 - loss: 0.4909\n",
      "Epoch 134/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7530 - loss: 0.5017\n",
      "Epoch 135/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7475 - loss: 0.5293  \n",
      "Epoch 136/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7588 - loss: 0.5086\n",
      "Epoch 137/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7193 - loss: 0.5274\n",
      "Epoch 138/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7653 - loss: 0.5013  \n",
      "Epoch 139/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7820 - loss: 0.4930  \n",
      "Epoch 140/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7638 - loss: 0.4966\n",
      "Epoch 141/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7350 - loss: 0.5839\n",
      "Epoch 142/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7716 - loss: 0.4753\n",
      "Epoch 143/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7961 - loss: 0.4537\n",
      "Epoch 144/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7542 - loss: 0.5008\n",
      "Epoch 145/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7379 - loss: 0.5376\n",
      "Epoch 146/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7658 - loss: 0.4896\n",
      "Epoch 147/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7878 - loss: 0.4760\n",
      "Epoch 148/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7415 - loss: 0.5122\n",
      "Epoch 149/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7574 - loss: 0.4946  \n",
      "Epoch 150/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7754 - loss: 0.4996  \n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 1 (expected 1)\n",
      "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
      "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 1 (expected 1)\n",
      "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
      "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 1 (expected 1)\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy tensorflow\n",
    "\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# load the dataset(PIMA-INDIANS-DIABETES)\n",
    "dataset = loadtxt(r'C:\\Users\\vinay\\Downloads\\pima-indians-diabetes.csv', delimiter=',')\n",
    "\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:, 0:8]\n",
    "y = dataset[:, 8]\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_shape=(8,), activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10, verbose=1)\n",
    "\n",
    "# make class predictions with the model\n",
    "predictions = (model.predict(X).flatten() > 0.5).astype(int)\n",
    "\n",
    "# summarize the first 5 cases\n",
    "for i in range(5):\n",
    "    print('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da8bc657-1b0a-4936-b157-106c7c3c9e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\vinay\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Train size: 105 samples\n",
      "Validation size: 15 samples\n",
      "Test size: 30 samples\n",
      "Epoch 1/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.2822 - loss: 1.3820 - val_accuracy: 0.5333 - val_loss: 1.0904\n",
      "Epoch 2/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3545 - loss: 1.1241 - val_accuracy: 0.5333 - val_loss: 1.0096\n",
      "Epoch 3/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4161 - loss: 1.0528 - val_accuracy: 0.5333 - val_loss: 1.0332\n",
      "Epoch 4/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5050 - loss: 1.0247 - val_accuracy: 0.3333 - val_loss: 1.0524\n",
      "Epoch 5/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4118 - loss: 1.0090 - val_accuracy: 0.3333 - val_loss: 1.0447\n",
      "Epoch 6/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4310 - loss: 0.9889 - val_accuracy: 0.3333 - val_loss: 1.0366\n",
      "Epoch 7/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4185 - loss: 0.9877 - val_accuracy: 0.4667 - val_loss: 1.0160\n",
      "Epoch 8/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5019 - loss: 0.9755 - val_accuracy: 0.5333 - val_loss: 1.0055\n",
      "Epoch 9/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5510 - loss: 0.9481 - val_accuracy: 0.5333 - val_loss: 0.9975\n",
      "Epoch 10/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7533 - loss: 0.9282 - val_accuracy: 0.5333 - val_loss: 0.9987\n",
      "Epoch 11/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6933 - loss: 0.9404 - val_accuracy: 0.7333 - val_loss: 0.9798\n",
      "Epoch 12/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8040 - loss: 0.9044 - val_accuracy: 0.5333 - val_loss: 0.9772\n",
      "Epoch 13/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7217 - loss: 0.8794 - val_accuracy: 0.4667 - val_loss: 0.9776\n",
      "Epoch 14/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7110 - loss: 0.8706 - val_accuracy: 0.5333 - val_loss: 0.9583\n",
      "Epoch 15/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7398 - loss: 0.8422 - val_accuracy: 0.4667 - val_loss: 0.9557\n",
      "Epoch 16/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6970 - loss: 0.8393 - val_accuracy: 0.4667 - val_loss: 0.9446\n",
      "Epoch 17/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6345 - loss: 0.8516 - val_accuracy: 0.5333 - val_loss: 0.9182\n",
      "Epoch 18/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7031 - loss: 0.8258 - val_accuracy: 0.5333 - val_loss: 0.9296\n",
      "Epoch 19/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7256 - loss: 0.7811 - val_accuracy: 0.4667 - val_loss: 0.9316\n",
      "Epoch 20/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6632 - loss: 0.7927 - val_accuracy: 0.4667 - val_loss: 0.9089\n",
      "Epoch 21/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6186 - loss: 0.7954 - val_accuracy: 0.5333 - val_loss: 0.8893\n",
      "Epoch 22/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6801 - loss: 0.7564 - val_accuracy: 0.5333 - val_loss: 0.8760\n",
      "Epoch 23/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7394 - loss: 0.6891 - val_accuracy: 0.4667 - val_loss: 0.8695\n",
      "Epoch 24/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6947 - loss: 0.7004 - val_accuracy: 0.6667 - val_loss: 0.8488\n",
      "Epoch 25/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7808 - loss: 0.6986 - val_accuracy: 0.6667 - val_loss: 0.8313\n",
      "Epoch 26/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8073 - loss: 0.6967 - val_accuracy: 0.6667 - val_loss: 0.8102\n",
      "Epoch 27/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8340 - loss: 0.6376 - val_accuracy: 0.6667 - val_loss: 0.8042\n",
      "Epoch 28/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8180 - loss: 0.6484 - val_accuracy: 0.6667 - val_loss: 0.7878\n",
      "Epoch 29/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8241 - loss: 0.6174 - val_accuracy: 0.6667 - val_loss: 0.7713\n",
      "Epoch 30/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8722 - loss: 0.6012 - val_accuracy: 0.6667 - val_loss: 0.7585\n",
      "Epoch 31/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8212 - loss: 0.5933 - val_accuracy: 0.6667 - val_loss: 0.7473\n",
      "Epoch 32/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7997 - loss: 0.5984 - val_accuracy: 0.6667 - val_loss: 0.7321\n",
      "Epoch 33/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8278 - loss: 0.5575 - val_accuracy: 0.7333 - val_loss: 0.7107\n",
      "Epoch 34/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8977 - loss: 0.5429 - val_accuracy: 0.6667 - val_loss: 0.7011\n",
      "Epoch 35/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8759 - loss: 0.5546 - val_accuracy: 0.7333 - val_loss: 0.6753\n",
      "Epoch 36/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9076 - loss: 0.5087 - val_accuracy: 0.7333 - val_loss: 0.6673\n",
      "Epoch 37/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9014 - loss: 0.5049 - val_accuracy: 0.7333 - val_loss: 0.6437\n",
      "Epoch 38/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9268 - loss: 0.5034 - val_accuracy: 0.7333 - val_loss: 0.6444\n",
      "Epoch 39/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9246 - loss: 0.4634 - val_accuracy: 0.7333 - val_loss: 0.6256\n",
      "Epoch 40/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8465 - loss: 0.5122 - val_accuracy: 0.8000 - val_loss: 0.6048\n",
      "Epoch 41/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9413 - loss: 0.4606 - val_accuracy: 0.7333 - val_loss: 0.6084\n",
      "Epoch 42/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9110 - loss: 0.4476 - val_accuracy: 0.8000 - val_loss: 0.5843\n",
      "Epoch 43/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9331 - loss: 0.4484 - val_accuracy: 0.7333 - val_loss: 0.5845\n",
      "Epoch 44/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9274 - loss: 0.4461 - val_accuracy: 0.8000 - val_loss: 0.5647\n",
      "Epoch 45/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9509 - loss: 0.4161 - val_accuracy: 0.8000 - val_loss: 0.5637\n",
      "Epoch 46/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9220 - loss: 0.4116 - val_accuracy: 0.8000 - val_loss: 0.5431\n",
      "Epoch 47/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9385 - loss: 0.4465 - val_accuracy: 0.8000 - val_loss: 0.5228\n",
      "Epoch 48/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9519 - loss: 0.3830 - val_accuracy: 0.8000 - val_loss: 0.5214\n",
      "Epoch 49/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9609 - loss: 0.3742 - val_accuracy: 0.8000 - val_loss: 0.5132\n",
      "Epoch 50/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9755 - loss: 0.3892 - val_accuracy: 0.8667 - val_loss: 0.4955\n",
      "Epoch 51/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9589 - loss: 0.3420 - val_accuracy: 0.8000 - val_loss: 0.4958\n",
      "Epoch 52/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9615 - loss: 0.3417 - val_accuracy: 0.8667 - val_loss: 0.4783\n",
      "Epoch 53/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9563 - loss: 0.3775 - val_accuracy: 0.8667 - val_loss: 0.4550\n",
      "Epoch 54/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9806 - loss: 0.3180 - val_accuracy: 0.8667 - val_loss: 0.4686\n",
      "Epoch 55/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9387 - loss: 0.3493 - val_accuracy: 0.8667 - val_loss: 0.4604\n",
      "Epoch 56/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9724 - loss: 0.3318 - val_accuracy: 0.8667 - val_loss: 0.4488\n",
      "Epoch 57/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9870 - loss: 0.3108 - val_accuracy: 0.8667 - val_loss: 0.4385\n",
      "Epoch 58/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9799 - loss: 0.2835 - val_accuracy: 0.8667 - val_loss: 0.4279\n",
      "Epoch 59/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9768 - loss: 0.3006 - val_accuracy: 0.8667 - val_loss: 0.4240\n",
      "Epoch 60/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9688 - loss: 0.3201 - val_accuracy: 0.8667 - val_loss: 0.4205\n",
      "Epoch 61/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9841 - loss: 0.2715 - val_accuracy: 0.8667 - val_loss: 0.4080\n",
      "Epoch 62/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9923 - loss: 0.2694 - val_accuracy: 0.8667 - val_loss: 0.3973\n",
      "Epoch 63/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9684 - loss: 0.2887 - val_accuracy: 0.8667 - val_loss: 0.4112\n",
      "Epoch 64/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.2664 - val_accuracy: 0.8667 - val_loss: 0.3807\n",
      "Epoch 65/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9940 - loss: 0.2471 - val_accuracy: 0.8667 - val_loss: 0.3955\n",
      "Epoch 66/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.2662 - val_accuracy: 0.8667 - val_loss: 0.3783\n",
      "Epoch 67/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9740 - loss: 0.2738 - val_accuracy: 0.8667 - val_loss: 0.3674\n",
      "Epoch 68/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9940 - loss: 0.2560 - val_accuracy: 0.8667 - val_loss: 0.3969\n",
      "Epoch 69/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9914 - loss: 0.2607 - val_accuracy: 0.8667 - val_loss: 0.3568\n",
      "Epoch 70/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.2593 - val_accuracy: 0.8667 - val_loss: 0.3586\n",
      "Epoch 71/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.2331 - val_accuracy: 0.8667 - val_loss: 0.3715\n",
      "Epoch 72/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9898 - loss: 0.2047 - val_accuracy: 0.8667 - val_loss: 0.3522\n",
      "Epoch 73/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9651 - loss: 0.2519 - val_accuracy: 0.8667 - val_loss: 0.3359\n",
      "Epoch 74/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9740 - loss: 0.2397 - val_accuracy: 0.8667 - val_loss: 0.3665\n",
      "Epoch 75/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9889 - loss: 0.2155 - val_accuracy: 0.8667 - val_loss: 0.3420\n",
      "Epoch 76/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9875 - loss: 0.2129 - val_accuracy: 0.8667 - val_loss: 0.3380\n",
      "Epoch 77/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.2143 - val_accuracy: 0.8667 - val_loss: 0.3237\n",
      "Epoch 78/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.2072 - val_accuracy: 0.8667 - val_loss: 0.3353\n",
      "Epoch 79/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.2269 - val_accuracy: 0.8667 - val_loss: 0.3234\n",
      "Epoch 80/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9841 - loss: 0.2028 - val_accuracy: 0.8667 - val_loss: 0.3337\n",
      "Epoch 81/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9888 - loss: 0.1817 - val_accuracy: 0.8667 - val_loss: 0.2993\n",
      "Epoch 82/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9737 - loss: 0.2223 - val_accuracy: 0.8667 - val_loss: 0.3171\n",
      "Epoch 83/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9758 - loss: 0.1798 - val_accuracy: 0.8667 - val_loss: 0.3167\n",
      "Epoch 84/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.2071 - val_accuracy: 0.8667 - val_loss: 0.3045\n",
      "Epoch 85/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.2001 - val_accuracy: 0.8667 - val_loss: 0.3261\n",
      "Epoch 86/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9707 - loss: 0.1853 - val_accuracy: 0.8667 - val_loss: 0.2999\n",
      "Epoch 87/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.1718 - val_accuracy: 0.8667 - val_loss: 0.3088\n",
      "Epoch 88/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9737 - loss: 0.1744 - val_accuracy: 0.8667 - val_loss: 0.2853\n",
      "Epoch 89/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.1772 - val_accuracy: 0.8667 - val_loss: 0.3081\n",
      "Epoch 90/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.1554 - val_accuracy: 0.8667 - val_loss: 0.2871\n",
      "Epoch 91/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9768 - loss: 0.1914 - val_accuracy: 0.8667 - val_loss: 0.2710\n",
      "Epoch 92/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.1494 - val_accuracy: 0.8667 - val_loss: 0.3099\n",
      "Epoch 93/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9849 - loss: 0.1608 - val_accuracy: 0.8667 - val_loss: 0.2950\n",
      "Epoch 94/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9740 - loss: 0.1623 - val_accuracy: 0.8667 - val_loss: 0.2552\n",
      "Epoch 95/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9688 - loss: 0.1702 - val_accuracy: 0.8667 - val_loss: 0.2838\n",
      "Epoch 96/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.1661 - val_accuracy: 0.8667 - val_loss: 0.2891\n",
      "Epoch 97/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.1337 - val_accuracy: 0.8667 - val_loss: 0.2835\n",
      "Epoch 98/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.1548 - val_accuracy: 0.8667 - val_loss: 0.2647\n",
      "Epoch 99/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9944 - loss: 0.1475 - val_accuracy: 0.8667 - val_loss: 0.2614\n",
      "Epoch 100/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9967 - loss: 0.1687 - val_accuracy: 0.8667 - val_loss: 0.2751\n",
      "Epoch 101/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9823 - loss: 0.1639 - val_accuracy: 0.8667 - val_loss: 0.2638\n",
      "Epoch 102/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.1563 - val_accuracy: 0.8667 - val_loss: 0.2711\n",
      "Epoch 103/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.1337 - val_accuracy: 0.8667 - val_loss: 0.2940\n",
      "Epoch 104/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9539 - loss: 0.1573 - val_accuracy: 0.8667 - val_loss: 0.2469\n",
      "Epoch 105/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.1384 - val_accuracy: 0.8667 - val_loss: 0.2880\n",
      "Epoch 106/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9768 - loss: 0.1375 - val_accuracy: 0.8667 - val_loss: 0.2781\n",
      "Epoch 107/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9844 - loss: 0.1160 - val_accuracy: 0.8667 - val_loss: 0.2527\n",
      "Epoch 108/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.1312 - val_accuracy: 0.8667 - val_loss: 0.2446\n",
      "Epoch 109/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.1302 - val_accuracy: 0.8667 - val_loss: 0.2676\n",
      "Epoch 110/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9893 - loss: 0.1241 - val_accuracy: 0.8667 - val_loss: 0.2489\n",
      "Epoch 111/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.1219 - val_accuracy: 0.8667 - val_loss: 0.2630\n",
      "Epoch 112/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9809 - loss: 0.1325 - val_accuracy: 0.8667 - val_loss: 0.2459\n",
      "Epoch 113/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9837 - loss: 0.1322 - val_accuracy: 0.8667 - val_loss: 0.2864\n",
      "Epoch 114/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.1340 - val_accuracy: 0.8667 - val_loss: 0.2435\n",
      "Epoch 115/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.1057 - val_accuracy: 0.8667 - val_loss: 0.2594\n",
      "Epoch 116/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9877 - loss: 0.1205 - val_accuracy: 0.8667 - val_loss: 0.2243\n",
      "Epoch 117/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.1262 - val_accuracy: 0.8667 - val_loss: 0.2893\n",
      "Epoch 118/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9893 - loss: 0.1078 - val_accuracy: 0.8667 - val_loss: 0.2504\n",
      "Epoch 119/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.1036 - val_accuracy: 0.8667 - val_loss: 0.2378\n",
      "Epoch 120/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9859 - loss: 0.1065 - val_accuracy: 0.8667 - val_loss: 0.2490\n",
      "Epoch 121/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9809 - loss: 0.1151 - val_accuracy: 0.8667 - val_loss: 0.2558\n",
      "Epoch 122/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 0.1012 - val_accuracy: 0.8667 - val_loss: 0.2819\n",
      "Epoch 123/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9682 - loss: 0.1227 - val_accuracy: 0.8667 - val_loss: 0.2128\n",
      "Epoch 124/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.0859 - val_accuracy: 0.8667 - val_loss: 0.2741\n",
      "Epoch 125/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9779 - loss: 0.1042 - val_accuracy: 0.8667 - val_loss: 0.2652\n",
      "Epoch 126/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9944 - loss: 0.1048 - val_accuracy: 0.8667 - val_loss: 0.2178\n",
      "Epoch 127/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9930 - loss: 0.0977 - val_accuracy: 0.8667 - val_loss: 0.2607\n",
      "Epoch 128/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9821 - loss: 0.1080 - val_accuracy: 0.8667 - val_loss: 0.2402\n",
      "Epoch 129/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9823 - loss: 0.1098 - val_accuracy: 0.8667 - val_loss: 0.2553\n",
      "Epoch 130/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9944 - loss: 0.1089 - val_accuracy: 0.8667 - val_loss: 0.2411\n",
      "Epoch 131/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9858 - loss: 0.1054 - val_accuracy: 0.8667 - val_loss: 0.2381\n",
      "Epoch 132/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0932 - val_accuracy: 0.8667 - val_loss: 0.2444\n",
      "Epoch 133/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9906 - loss: 0.0790 - val_accuracy: 0.8667 - val_loss: 0.2263\n",
      "Epoch 134/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9684 - loss: 0.0904 - val_accuracy: 0.8667 - val_loss: 0.2477\n",
      "Epoch 135/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9930 - loss: 0.0902 - val_accuracy: 0.8667 - val_loss: 0.2590\n",
      "Epoch 136/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.0944 - val_accuracy: 0.8667 - val_loss: 0.2439\n",
      "Epoch 137/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.0980 - val_accuracy: 0.8667 - val_loss: 0.2482\n",
      "Epoch 138/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9956 - loss: 0.0916 - val_accuracy: 0.8667 - val_loss: 0.2671\n",
      "Epoch 139/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0923 - val_accuracy: 0.8667 - val_loss: 0.2404\n",
      "Epoch 140/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9768 - loss: 0.0803 - val_accuracy: 0.8667 - val_loss: 0.2423\n",
      "Epoch 141/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9740 - loss: 0.0998 - val_accuracy: 0.8667 - val_loss: 0.2628\n",
      "Epoch 142/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9930 - loss: 0.0899 - val_accuracy: 0.8667 - val_loss: 0.2587\n",
      "Epoch 143/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9740 - loss: 0.0853 - val_accuracy: 0.8667 - val_loss: 0.2331\n",
      "Epoch 144/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9823 - loss: 0.0875 - val_accuracy: 0.8667 - val_loss: 0.2393\n",
      "Epoch 145/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0776 - val_accuracy: 0.8667 - val_loss: 0.2627\n",
      "Epoch 146/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9795 - loss: 0.0897 - val_accuracy: 0.8667 - val_loss: 0.2181\n",
      "Epoch 147/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.0825 - val_accuracy: 0.8667 - val_loss: 0.2462\n",
      "Epoch 148/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0714 - val_accuracy: 0.8667 - val_loss: 0.2547\n",
      "Epoch 149/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9837 - loss: 0.0698 - val_accuracy: 0.8667 - val_loss: 0.2219\n",
      "Epoch 150/150\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9779 - loss: 0.0758 - val_accuracy: 0.8667 - val_loss: 0.2522\n",
      "\n",
      "Test Loss: 0.1082\n",
      "\n",
      "Test Accuracy: 96.67%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │            \u001b[38;5;34m60\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m27\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">575</span> (2.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m575\u001b[0m (2.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">191</span> (764.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m191\u001b[0m (764.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "\n",
    "# Import libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load Dataset(IRIS)\n",
    "data = load_iris()\n",
    "x = data.data\n",
    "y = data.target\n",
    "\n",
    "# Step 1: First split into train+val (80%) and test (20%)\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Split train_val into train (70%) and val (10%)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.125, random_state=42)\n",
    "\n",
    "print(f\"Train size: {x_train.shape[0]} samples\")\n",
    "print(f\"Validation size: {x_val.shape[0]} samples\")\n",
    "print(f\"Test size: {x_test.shape[0]} samples\")\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=4, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit model\n",
    "model.fit(x_train, y_train, epochs=150, batch_size=10, validation_data=(x_val, y_val), verbose=1)\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\nTest Loss: {loss:.4f}\")\n",
    "print(f\"\\nTest Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c5afc-1661-4927-9fb1-aef3a4d0f46e",
   "metadata": {},
   "source": [
    "# Digit Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88f55220-4916-43e2-be16-1bb90fe50e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinay\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8514 - loss: 0.5132 - val_accuracy: 0.9573 - val_loss: 0.1545\n",
      "Epoch 2/5\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9513 - loss: 0.1612 - val_accuracy: 0.9677 - val_loss: 0.1040\n",
      "Epoch 3/5\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9656 - loss: 0.1130 - val_accuracy: 0.9740 - val_loss: 0.0859\n",
      "Epoch 4/5\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0938 - val_accuracy: 0.9755 - val_loss: 0.0816\n",
      "Epoch 5/5\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.0741 - val_accuracy: 0.9780 - val_loss: 0.0759\n",
      "313/313 - 0s - 1ms/step - accuracy: 0.9761 - loss: 0.0758\n",
      "\n",
      "Test Loss: 0.0758\n",
      "\n",
      "Test Accuracy: 97.61%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pip install tensorflow\n",
    "#%pip install scikit-learn\n",
    "\n",
    "#Importing libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import models , layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#load dataset(MNIST)\n",
    "(x_train_val,y_train_val),(x_test,y_test) = mnist.load_data()\n",
    "\n",
    "#normalize\n",
    "x_train_val = x_train_val / 255.0\n",
    "x_test = x_test  / 255.0\n",
    "\n",
    "#split training data into 70-10\n",
    "x_train,x_val,y_train,y_val = train_test_split(\n",
    "    x_train_val,y_train_val,\n",
    "    test_size= 0.125,\n",
    "    random_state = 42)\n",
    "\n",
    "#define model\n",
    "model = Sequential([\n",
    "    layers.Flatten(input_shape =(28,28)),\n",
    "    layers.Dense(128,activation = 'relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10,activation = 'softmax')])\n",
    "\n",
    "#Compile model\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', \n",
    "              optimizer = 'adam', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "#Fit Model\n",
    "history = model.fit(x_train, y_train, epochs =  5, validation_data = (x_val , y_val))\n",
    "\n",
    "#evaluate model\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"\\nTest Loss: {loss:.4f}\")\n",
    "print(f\"\\nTest Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "#Prediction\n",
    "predictions = model.predict(x_test[:5])\n",
    "\n",
    "#with image\n",
    "for i in range(5):\n",
    "    plt.imshow(x_test[i],cmap = plt.cm.binary)\n",
    "    plt.title(f\"Prediction : {predictions[i].argmax()}  (True Label:{y_test[i]})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155d0c7a-b321-4e55-9d98-5f5752af2839",
   "metadata": {},
   "source": [
    "# RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11f7edc2-2366-431c-b292-22c6635ddce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6040273260150124\n",
      "[[0.22623906 0.04037948 0.00462676 ... 0.02687533 0.49337997 0.04493018]\n",
      " [0.16360664 0.71321579 0.04123763 ... 0.17491054 0.06019696 0.2064841 ]\n",
      " [0.13288533 0.33002921 0.08625566 ... 0.20179262 0.10196891 0.24457337]\n",
      " ...\n",
      " [0.06290198 0.10406802 0.01353547 ... 0.17294638 0.04505126 0.10862845]\n",
      " [0.09794316 0.21956812 0.02331123 ... 0.31411128 0.0604904  0.52686974]\n",
      " [0.18974665 0.53411449 0.04599081 ... 0.22177704 0.06293893 0.21717651]]\n",
      "[ 1.32116003 -0.07605856  0.233921   -0.04185379  0.08965373  0.01724168\n",
      " -0.58224842 -0.1346137 ]\n",
      "[0.12311405 0.62480415 0.025777   0.3268271  0.34546934 0.1621497\n",
      " 0.06256219 0.22677447]\n",
      "0.8853844112182606\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#Import data\n",
    "data = pd.read_csv(r\"C:\\Users\\vinay\\Downloads\\bank-full.csv\")\n",
    "cols = [\"age\",\"balance\",\"day\",\"duration\",\"campaign\",\"pdays\",\"previous\"]\n",
    "data_encode = data.drop(cols,axis=1)\n",
    "data_encode = data_encode.apply(LabelEncoder().fit_transform)\n",
    "data_rest = data[cols]\n",
    "data = pd.concat([data_rest,data_encode],axis=1)\n",
    "\n",
    "#split data\n",
    "data_train,data_test = train_test_split(data ,test_size = 0.5 , random_state = 4)\n",
    "x_train = data_train.drop(\"y\",axis=1)\n",
    "y_train = data_train[\"y\"]\n",
    "x_test = data_test.drop(\"y\",axis=1)\n",
    "y_test = data_test[\"y\"]\n",
    " \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "k_cent = 8\n",
    "km = KMeans(n_clusters = k_cent , max_iter = 100)\n",
    "km.fit(x_train)\n",
    "cent = km.cluster_centers_\n",
    "max=0\n",
    "for i in range(k_cent):\n",
    "  for j in range(k_cent):\n",
    "    d = np.linalg.norm(cent[i] - cent[j])\n",
    "    if d > max :\n",
    "      max = d\n",
    "d = max\n",
    "sigma = d/math.sqrt(2 * k_cent)\n",
    "print(sigma)\n",
    "shape = x_train.shape\n",
    "row = shape[0]\n",
    "column = k_cent\n",
    "G = np.empty((row,column),dtype=float)\n",
    "for i in range(row):\n",
    "  for j in range(column):\n",
    "    dist = np.linalg.norm(x_train[i] - cent[j])\n",
    "    G[i][j] = math.exp(-math.pow(dist,2)/math.pow(2*sigma,2))\n",
    "print(G)\n",
    "GTG = np.dot(G.T,G)\n",
    "GTG_inv = np.linalg.inv(GTG)\n",
    "fac =np.dot(GTG_inv,G.T)\n",
    "W = np.dot(fac,y_train)\n",
    "print(W)\n",
    "row = x_test.shape[0]\n",
    "column = k_cent\n",
    "G_test = np.empty((row,column),dtype=float)\n",
    "for i in range(row):\n",
    "  for j in range(column):\n",
    "    dist = np.linalg.norm(x_test[i] - cent[j])\n",
    "    G_test[i][j] = math.exp(-math.pow(dist,2)/math.pow(2*sigma,2))\n",
    "print(G_test[0])\n",
    "prediction = np.dot(G_test,W)\n",
    "prediction = 0.5 * (np.sign(prediction - 0.5) + 1)\n",
    "score = accuracy_score(prediction,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f8955-0631-42b7-b5cd-e70dc76660e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
      "0           11.6             0.580         0.66            2.20      0.074   \n",
      "1           10.4             0.610         0.49            2.10      0.200   \n",
      "2            7.4             1.185         0.00            4.25      0.097   \n",
      "3           10.4             0.440         0.42            1.50      0.145   \n",
      "4            8.3             1.020         0.02            3.40      0.084   \n",
      "\n",
      "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
      "0                 10.0                  47.0  1.00080  3.25       0.57   \n",
      "1                  5.0                  16.0  0.99940  3.16       0.63   \n",
      "2                  5.0                  14.0  0.99660  3.63       0.54   \n",
      "3                 34.0                  48.0  0.99832  3.38       0.86   \n",
      "4                  6.0                  11.0  0.99892  3.48       0.49   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.0        3  \n",
      "1      8.4        3  \n",
      "2     10.7        3  \n",
      "3      9.9        3  \n",
      "4     11.0        3  \n"
     ]
    }
   ],
   "source": [
    "#KERNEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "data = pd.read_csv(r'C:\\Users\\vinay\\Downloads\\wine_data.csv')\n",
    "print(data.head())\n",
    " \n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    " \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    " \n",
    "def rbf_kernel(x1, x2, gamma=1.0):\n",
    "  diff = x1 - x2\n",
    "  return np.exp(-gamma * np.dot(diff, diff.T))\n",
    " \n",
    "def rbf_classifier(X_train, y_train, X_test, gamma):\n",
    "  predictions = []\n",
    "  for test_sample in X_test:\n",
    "    distances = []\n",
    "    for train_sample in X_train:\n",
    "      distance = rbf_kernel(test_sample, train_sample, gamma)\n",
    "      distances.append(distance)\n",
    "      closest_index = np.argmax(distances)\n",
    "      predictions.append(y_train[closest_index])\n",
    "  return np.array(predictions)\n",
    " \n",
    "predictions = rbf_classifier(X_train, y_train, X_test, gamma=0.5)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e41b3cc-6add-4eb5-b105-65fdef0b0d7f",
   "metadata": {},
   "source": [
    "# Multilayer-perceptron: Back-Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef831bf0-4e9e-4477-b756-e286dfbb58a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from random import random\n",
    "from random import seed\n",
    "\n",
    "def initialize_network(n_inputs, n_hiddens, n_outputs):\n",
    "  network = list()\n",
    "  hidden_layer = [{'weights':[random() for i in range(n_inputs+1)]}for i in range(n_hiddens)]\n",
    "  network.append(hidden_layer)\n",
    "  output_layer = [{'weights':[random() for i in range(n_hiddens+1)]}for i in range(n_outputs)]\n",
    "  network.append(output_layer)\n",
    "  return network\n",
    "seed(1)\n",
    "network = initialize_network(2,1,2)\n",
    "for layer in network:\n",
    "  print(layer)\n",
    "\n",
    "#bias is the last value of array\n",
    "def activate(weights, inputs):\n",
    "  activation = weights[-1]\n",
    "  for i in range(len(weights)-1):\n",
    "    activation += weights[i] * inputs[i]\n",
    "  return activation\n",
    "\n",
    "#in exam, hyperbolic tangent or loop\n",
    "# sigmoid equation\n",
    "from math import exp\n",
    "def transfer(activation):\n",
    "\treturn 1.0 / (1.0 + exp(-activation))\n",
    "\n",
    "#at last we get output of the output function\n",
    "def forward_propagate(network, row):\n",
    "  inputs = row\n",
    "  for layer in network:\n",
    "    new_inputs = []\n",
    "    for neuron in layer:\n",
    "      activation = activate(neuron['weights'], inputs)\n",
    "      neuron['output'] = transfer(activation)\n",
    "      new_inputs.append(neuron['output'])\n",
    "    inputs = new_inputs\n",
    "  return inputs\n",
    "#test forward propagation\n",
    "network = [[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
    " [{'weights': [0.2550690257394217, 0.49543508709194095]},\n",
    "  {'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
    "row = [1,0,None]\n",
    "output = forward_propagate(network, row)\n",
    "print(output)\n",
    "\n",
    "#calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "  return output * (1.0 - output)\n",
    "\n",
    "#first for loop: layer then neuron then the no of outputs\n",
    "def backward_propagate_error(network, expected):\n",
    "  for i in reversed(range(len(network))):\n",
    "    layer = network[i]\n",
    "    errors = list()\n",
    "    if i != len(network)-1:\n",
    "      for j in range(len(layer)):\n",
    "        error = 0.0\n",
    "        for neuron in network[i+1]:\n",
    "          error += (neuron['weights'][j] * neuron['delta'])\n",
    "        errors.append(error)\n",
    "    else:\n",
    "      for j in range(len(layer)):\n",
    "        neuron = layer[j]\n",
    "        errors.append(neuron['output']-expected[j])\n",
    "    for j in range(len(layer)):\n",
    "      neuron = layer[j]\n",
    "      neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    "\n",
    "#test backpropagation of error\n",
    "network = [[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
    "\t\t[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095]}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
    "expected = [0, 1]\n",
    "backward_propagate_error(network, expected)\n",
    "for layer in network:\n",
    "\tprint(layer)\n",
    "\n",
    "#Update network weights with error\n",
    "def update_weights(network, row, l_rate):\n",
    "\tfor i in range(len(network)):\n",
    "\t\tinputs = row[:-1]\n",
    "\t\tif i != 0:\n",
    "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "\t\tfor neuron in network[i]:\n",
    "\t\t\tfor j in range(len(inputs)):\n",
    "\t\t\t\tneuron['weights'][j] -= l_rate * neuron['delta'] * inputs[j]\n",
    "\t\t\tneuron['weights'][-1] -= l_rate * neuron['delta']\n",
    "\n",
    "#Train a network for a fixed number of epochs\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tsum_error = 0\n",
    "\t\tfor row in train:\n",
    "\t\t\toutputs = forward_propagate(network, row)\n",
    "\t\t\texpected = [0 for i in range(n_outputs)]\n",
    "\t\t\texpected[row[-1]] = 1\n",
    "\t\t\tsum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "\t\t\tbackward_propagate_error(network, expected)\n",
    "\t\t\tupdate_weights(network, row, l_rate)\n",
    "\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "\n",
    "#Test training backprop algorithm\n",
    "seed(1)\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "\t[1.465489372,2.362125076,0],\n",
    "\t[3.396561688,4.400293529,0],\n",
    "\t[1.38807019,1.850220317,0],\n",
    "\t[3.06407232,3.005305973,0],\n",
    "\t[7.627531214,2.759262235,1],\n",
    "\t[5.332441248,2.088626775,1],\n",
    "\t[6.922596716,1.77106367,1],\n",
    "\t[8.675418651,-0.242068655,1],\n",
    "\t[7.673756466,3.508563011,1]]\n",
    "n_inputs = len(dataset[0]) - 1\n",
    "n_outputs = len(set([row[-1] for row in dataset]))\n",
    "network = initialize_network(n_inputs, 2, n_outputs)\n",
    "train_network(network, dataset, 0.5, 20, n_outputs)\n",
    "for layer in network:\n",
    "  print(layer)\n",
    "\n",
    "#Make a prediction with a network\n",
    "def predict(network, row):\n",
    "\toutputs = forward_propagate(network, row)\n",
    "\treturn outputs.index(max(outputs))\n",
    "#testing predictions\n",
    "network = [[{'weights': [-1.4688375095432327, 1.850887325439514, 1.0858178629550297], 'output': 0.029980305604426185, 'delta': 0.0059546604162323625}, {'weights': [0.37711098142462157, -0.0625909894552989, 0.2765123702642716], 'output': 0.9456229000211323, 'delta': -0.0026279652850863837}],\n",
    " [{'weights': [2.515394649397849, -0.3391927502445985, -0.9671565426390275], 'output': 0.23648794202357587, 'delta': 0.04270059278364587}, {'weights': [-2.5584149848484263, 1.0036422106209202, 0.42383086467582715], 'output': 0.7790535202438367, 'delta': -0.03803132596437354}]]\n",
    "for row in dataset:\n",
    "  prediction = predict(network, row)\n",
    "  print('Expected=%d, Got=%d' % (row[-1], prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec7d810-0542-4f6e-88b3-2869c8107549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
